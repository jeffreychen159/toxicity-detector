# Toxicity Classifier

## Overview
This project aims to test different models and analyze how well each model detects toxicity in text. This project tests

## Features
- Binary classification of text comments
- Multi label toxicity classifier
- Preprocesses and tokenizes input data
- Analysis of different toxicity models

## Installation
```bash
pip install -r requirements.txt
```

## Usage
All training is either done in the Google Colab file or the ```train_wikipedia.py``` file

## Dataset
Train the model on labeled toxic/non-toxic comment datasets.

## Results
Document model performance metrics and accuracy scores here.